{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is for SSA-LSTM model\n",
    "- 0.9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import IPython\n",
    "    import IPython.display\n",
    "    from IPython.display import clear_output\n",
    "    import matplotlib.pyplot as plt\n",
    "    import sys\n",
    "\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Flatten, Dense, Dropout\n",
    "\n",
    "    ## Read in my python class\n",
    "    from Window_Generator_package import Window_Generator\n",
    "\n",
    "    train_path = './Data/Parameter_tuning_0.9995/504/Train/'\n",
    "    test_path = './Data/Parameter_tuning_0.9995/504/Test/'\n",
    "    full_path = './Data/Grouped/'\n",
    "\n",
    "    # stock_example = pd.read_csv(path + 'Data/Grouped/Consumer and Service Sectors/ALL.AX.csv')\n",
    "    def read_stock(path, file_name):\n",
    "        stock = pd.read_csv(path + file_name, header = [0])\n",
    "        stock_index = pd.to_datetime(stock['Date'])\n",
    "        stock.index = stock_index\n",
    "        stock = stock.drop('Date', axis = 1)\n",
    "        return stock\n",
    "    group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "    index = [0, 1, 2]\n",
    "    def read_all(the_path):\n",
    "        All_df = []\n",
    "        files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "\n",
    "        for name in files:\n",
    "            stock = read_stock(the_path + '/', name)\n",
    "            All_df.append(stock)\n",
    "        return All_df, files\n",
    "    train_All_df_0, train_files = read_all(train_path + group[index[0]])\n",
    "    test_All_df_0, test_files = read_all(test_path + group[index[0]])\n",
    "    full_All_df_0, full_files = read_all(full_path + group[index[0]])\n",
    "    example_train = train_All_df_0[0]\n",
    "    example_test = test_All_df_0[0]\n",
    "    example_actual = full_All_df_0[0][5:]\n",
    "\n",
    "    train_series_1 = example_train.iloc[:, 0]\n",
    "    test_series_1 = example_test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    MAX_EPOCHS = 30\n",
    "\n",
    "    def compile_and_fit(model, X_train, Y_train, patience=5):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "        history = model.fit(X_train, Y_train, epochs=MAX_EPOCHS, verbose = 0)\n",
    "        return history\n",
    "\n",
    "\n",
    "    def lstm_model(window_length):\n",
    "        lstm = Sequential()\n",
    "        lstm.add(LSTM(128, kernel_regularizer= 'l2'))\n",
    "        lstm.add(Dropout(0.3))\n",
    "        lstm.add(Dense(64, activation='relu'))\n",
    "        lstm.add(Dense(1, activation = 'linear'))\n",
    "        return lstm\n",
    "\n",
    "    lstm = lstm_model(window_length = 5)\n",
    "\n",
    "    def obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = 5):\n",
    "        # The input train and test are all 3D list\n",
    "        predicted_train_list = []\n",
    "        predicted_test_list = []\n",
    "        train_MAE_list = []\n",
    "        test_MAE_list = []\n",
    "        for i in range(5):\n",
    "            lstm = lstm_model(window_length)\n",
    "            history = compile_and_fit(lstm, X_train = X_train, Y_train = Y_train)\n",
    "            # IPython.display.clear_output()\n",
    "            train_performance = lstm.evaluate(X_train, Y_train)[1]\n",
    "            test_performance = lstm.evaluate(X_test, Y_test)[1]\n",
    "            # print('Train:', str(train_performance))\n",
    "            # print('Test:', str(test_performance))\n",
    "            Y_predict_train = lstm.predict(X_train)\n",
    "            Y_predict_train = Y_predict_train.reshape(len(Y_predict_train))\n",
    "            predicted_train_list.append(Y_predict_train)\n",
    "\n",
    "            Y_predict_test = lstm.predict(X_test)\n",
    "            Y_predict_test = Y_predict_test.reshape(len(Y_predict_test))\n",
    "            predicted_test_list.append(Y_predict_test)\n",
    "\n",
    "            train_MAE_list.append(train_performance)\n",
    "            test_MAE_list.append(test_performance)\n",
    "\n",
    "        train_MAE = np.mean(train_MAE_list)\n",
    "        test_MAE = np.mean(test_MAE_list)\n",
    "\n",
    "        predicted_train_list = np.array(predicted_train_list)\n",
    "        predicted_train_list = np.mean(predicted_train_list, axis = 0)\n",
    "        predicted_test_list = np.array(predicted_test_list)\n",
    "        predicted_test_list = np.mean(predicted_test_list, axis = 0)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        return predicted_train_list, predicted_test_list, train_MAE, test_MAE\n",
    "\n",
    "    # Get result of 1 train and test series\n",
    "    def obtain_ONE_series(train_series, test_series, window_length = 5, show = None):\n",
    "\n",
    "        # Data Preparation\n",
    "        w = Window_Generator(train_series = train_series, test_series = test_series)\n",
    "        _, _, train_mean, train_std, test_mean, test_std = w.standardization(show=True)\n",
    "        _, _, _, _ = w.window_generation(show = True)\n",
    "        X_train, X_test, Y_train, Y_test = w.data_getter()\n",
    "        train_denormalized = w.denormalize_train()\n",
    "        test_denormalized = w.denormalize_test()\n",
    "\n",
    "        # Training and Prediction\n",
    "        predicted_train_list, predicted_test_list, train_MAE, test_MAE = obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = window_length)\n",
    "        # print('Train_MAE:', train_MAE)\n",
    "        # print('Test_MAE:', test_MAE)\n",
    "\n",
    "        # Prediction Generation (Are train_set)\n",
    "\n",
    "        train_index = w.train_index[w.window_length:]\n",
    "        test_index = w.test_index\n",
    "\n",
    "        Y_predict_train = pd.Series(predicted_train_list, index = train_index)\n",
    "        Y_predict_train = Y_predict_train * train_std[w.window_length:] + train_mean[w.window_length:]\n",
    "        Y_actual_train = Y_train.reshape(len(Y_train)) * train_std[w.window_length:] + train_mean[w.window_length:]\n",
    "        Y_predict_train = pd.DataFrame(Y_predict_train, index = train_index)\n",
    "        Y_actual_train = pd.DataFrame(Y_actual_train, index = train_index)\n",
    "\n",
    "        Y_predict_test = pd.Series(predicted_test_list, index = test_index)\n",
    "        Y_predict_test = Y_predict_test * test_std + test_mean\n",
    "        Y_actual_test = Y_test.reshape(len(Y_test)) * test_std + test_mean\n",
    "        Y_predict_test = pd.DataFrame(Y_predict_test, index = test_index)\n",
    "        Y_actual_test = pd.DataFrame(Y_actual_test, index = test_index)\n",
    "\n",
    "        # if (show != None):\n",
    "        #   plt.plot(Y_actual_train, label = 'Train Actual')\n",
    "        #   plt.plot(Y_predict_train, label = 'Train predict')\n",
    "        #   plt.plot(Y_actual_test, label = 'Test Actual')\n",
    "        #   plt.plot(Y_predict_test, label = 'Test predict')\n",
    "        #   plt.legend()\n",
    "        #   plt.show()\n",
    "\n",
    "        return Y_actual_train, Y_predict_train, Y_actual_test, Y_predict_test\n",
    "\n",
    "    def obtain_ONE_stock(train, test, show = None):\n",
    "        length = len(train.columns)\n",
    "        actual_train = []\n",
    "        predict_train = []\n",
    "        actual_test = []\n",
    "        predict_test = []\n",
    "        for i in range(length):\n",
    "            train_series = train.iloc[:, i]\n",
    "            test_series = test.iloc[:, i]\n",
    "            Series_actual_train, Series_predict_train, Series_actual_test, Series_predict_test = obtain_ONE_series(train_series, test_series, window_length = 5, show = show)\n",
    "            actual_train.append(Series_actual_train)\n",
    "            predict_train.append(Series_predict_train)\n",
    "            actual_test.append(Series_actual_test)\n",
    "            predict_test.append(Series_predict_test)\n",
    "\n",
    "        final_actual_train = pd.concat(actual_train)\n",
    "        final_actual_train = final_actual_train.groupby(final_actual_train.index).sum()\n",
    "\n",
    "        final_predict_train = pd.concat(predict_train)\n",
    "        final_predict_train = final_predict_train.groupby(final_predict_train.index).sum()\n",
    "\n",
    "        final_actual_test = pd.concat(actual_test)\n",
    "        final_actual_test = final_actual_test.groupby(final_actual_test.index).sum()\n",
    "\n",
    "        final_predict_test = pd.concat(predict_test)\n",
    "        final_predict_test = final_predict_test.groupby(final_predict_test.index).sum()\n",
    "        # if (show != None):\n",
    "        #     plt.plot(final_actual_train, label = 'Train Actual')\n",
    "        #     plt.plot(final_predict_train, label = 'Train predict')\n",
    "        #     plt.plot(final_actual_test, label = 'Test Actual')\n",
    "        #     plt.plot(final_predict_test, label = 'Test predict')\n",
    "        #     plt.legend()\n",
    "        #     plt.show()\n",
    "\n",
    "        return final_actual_train, final_predict_train, final_actual_test, final_predict_test\n",
    "\n",
    "\n",
    "    final_actual_train, final_predict_train, final_actual_test, final_predict_test = obtain_ONE_stock(example_train, example_test, show = True)\n",
    "\n",
    "    Y_result = pd.concat([pd.concat([final_actual_train, final_predict_train], axis = 1), pd.concat([final_actual_test, final_predict_test], axis = 1)], axis = 0)\n",
    "    Y_result.columns = ['Smoothed_Actual', 'Predict']\n",
    "    Y_result = pd.concat([example_actual, Y_result], axis = 1)\n",
    "\n",
    "    store_path = './Data/Parameter_tuning_0.9995/504_Prediction/SSA-CNN/'\n",
    "    def obtain_all(the_index, window_length = 5, show = None):\n",
    "        group_name = group[index[the_index]]\n",
    "        train_All_df, train_files = read_all(train_path + group_name)\n",
    "        test_All_df, test_files = read_all(test_path + group_name)\n",
    "        full_All_df, full_files = read_all(full_path + group_name)\n",
    "        total_length = len(full_All_df)\n",
    "\n",
    "        for i in range(total_length):\n",
    "            stock_name = full_files[i]\n",
    "            train_series = train_All_df[i]\n",
    "            test_series = test_All_df[i]\n",
    "            final_actual_train, final_predict_train, final_actual_test, final_predict_test = obtain_ONE_stock(train_series, test_series, show = show)\n",
    "\n",
    "            actual = full_All_df[i][5:]\n",
    "            Y_result = pd.concat([pd.concat([final_actual_train, final_predict_train], axis = 1), pd.concat([final_actual_test, final_predict_test], axis = 1)], axis = 0)\n",
    "            Y_result.columns = ['Smoothed_Actual', 'Predict']\n",
    "            Y_result = pd.concat([actual, Y_result], axis = 1)\n",
    "            Y_result.to_csv(store_path + group_name + '/' + stock_name)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    obtain_all(idx, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is for SSA-LSTM model\n",
    "- 0.9997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import IPython\n",
    "    import IPython.display\n",
    "    from IPython.display import clear_output\n",
    "    import matplotlib.pyplot as plt\n",
    "    import sys\n",
    "\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Flatten, Dense, Dropout\n",
    "\n",
    "    ## Read in my python class\n",
    "    from Window_Generator_package import Window_Generator\n",
    "\n",
    "    train_path = './Data/Parameter_tuning_0.9997/504/Train/'\n",
    "    test_path = './Data/Parameter_tuning_0.9997/504/Test/'\n",
    "    full_path = './Data/Grouped/'\n",
    "\n",
    "    # stock_example = pd.read_csv(path + 'Data/Grouped/Consumer and Service Sectors/ALL.AX.csv')\n",
    "    def read_stock(path, file_name):\n",
    "        stock = pd.read_csv(path + file_name, header = [0])\n",
    "        stock_index = pd.to_datetime(stock['Date'])\n",
    "        stock.index = stock_index\n",
    "        stock = stock.drop('Date', axis = 1)\n",
    "        return stock\n",
    "    group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "    index = [0, 1, 2]\n",
    "    def read_all(the_path):\n",
    "        All_df = []\n",
    "        files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "\n",
    "        for name in files:\n",
    "            stock = read_stock(the_path + '/', name)\n",
    "            All_df.append(stock)\n",
    "        return All_df, files\n",
    "    train_All_df_0, train_files = read_all(train_path + group[index[0]])\n",
    "    test_All_df_0, test_files = read_all(test_path + group[index[0]])\n",
    "    full_All_df_0, full_files = read_all(full_path + group[index[0]])\n",
    "    example_train = train_All_df_0[0]\n",
    "    example_test = test_All_df_0[0]\n",
    "    example_actual = full_All_df_0[0][5:]\n",
    "\n",
    "    train_series_1 = example_train.iloc[:, 0]\n",
    "    test_series_1 = example_test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    MAX_EPOCHS = 30\n",
    "\n",
    "    def compile_and_fit(model, X_train, Y_train, patience=5):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "        history = model.fit(X_train, Y_train, epochs=MAX_EPOCHS, verbose = 0)\n",
    "        return history\n",
    "\n",
    "\n",
    "    def lstm_model(window_length):\n",
    "        lstm = Sequential()\n",
    "        lstm.add(LSTM(128, kernel_regularizer= 'l2'))\n",
    "        lstm.add(Dropout(0.3))\n",
    "        lstm.add(Dense(64, activation='relu'))\n",
    "        lstm.add(Dense(1, activation = 'linear'))\n",
    "        return lstm\n",
    "\n",
    "    lstm = lstm_model(window_length = 5)\n",
    "\n",
    "    def obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = 5):\n",
    "        # The input train and test are all 3D list\n",
    "        predicted_train_list = []\n",
    "        predicted_test_list = []\n",
    "        train_MAE_list = []\n",
    "        test_MAE_list = []\n",
    "        for i in range(5):\n",
    "            lstm = lstm_model(window_length)\n",
    "            history = compile_and_fit(lstm, X_train = X_train, Y_train = Y_train)\n",
    "            # IPython.display.clear_output()\n",
    "            train_performance = lstm.evaluate(X_train, Y_train)[1]\n",
    "            test_performance = lstm.evaluate(X_test, Y_test)[1]\n",
    "            # print('Train:', str(train_performance))\n",
    "            # print('Test:', str(test_performance))\n",
    "            Y_predict_train = lstm.predict(X_train)\n",
    "            Y_predict_train = Y_predict_train.reshape(len(Y_predict_train))\n",
    "            predicted_train_list.append(Y_predict_train)\n",
    "\n",
    "            Y_predict_test = lstm.predict(X_test)\n",
    "            Y_predict_test = Y_predict_test.reshape(len(Y_predict_test))\n",
    "            predicted_test_list.append(Y_predict_test)\n",
    "\n",
    "            train_MAE_list.append(train_performance)\n",
    "            test_MAE_list.append(test_performance)\n",
    "\n",
    "        train_MAE = np.mean(train_MAE_list)\n",
    "        test_MAE = np.mean(test_MAE_list)\n",
    "\n",
    "        predicted_train_list = np.array(predicted_train_list)\n",
    "        predicted_train_list = np.mean(predicted_train_list, axis = 0)\n",
    "        predicted_test_list = np.array(predicted_test_list)\n",
    "        predicted_test_list = np.mean(predicted_test_list, axis = 0)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        return predicted_train_list, predicted_test_list, train_MAE, test_MAE\n",
    "\n",
    "    # Get result of 1 train and test series\n",
    "    def obtain_ONE_series(train_series, test_series, window_length = 5, show = None):\n",
    "\n",
    "        # Data Preparation\n",
    "        w = Window_Generator(train_series = train_series, test_series = test_series)\n",
    "        _, _, train_mean, train_std, test_mean, test_std = w.standardization(show=True)\n",
    "        _, _, _, _ = w.window_generation(show = True)\n",
    "        X_train, X_test, Y_train, Y_test = w.data_getter()\n",
    "        train_denormalized = w.denormalize_train()\n",
    "        test_denormalized = w.denormalize_test()\n",
    "\n",
    "        # Training and Prediction\n",
    "        predicted_train_list, predicted_test_list, train_MAE, test_MAE = obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = window_length)\n",
    "        # print('Train_MAE:', train_MAE)\n",
    "        # print('Test_MAE:', test_MAE)\n",
    "\n",
    "        # Prediction Generation (Are train_set)\n",
    "\n",
    "        train_index = w.train_index[w.window_length:]\n",
    "        test_index = w.test_index\n",
    "\n",
    "        Y_predict_train = pd.Series(predicted_train_list, index = train_index)\n",
    "        Y_predict_train = Y_predict_train * train_std[w.window_length:] + train_mean[w.window_length:]\n",
    "        Y_actual_train = Y_train.reshape(len(Y_train)) * train_std[w.window_length:] + train_mean[w.window_length:]\n",
    "        Y_predict_train = pd.DataFrame(Y_predict_train, index = train_index)\n",
    "        Y_actual_train = pd.DataFrame(Y_actual_train, index = train_index)\n",
    "\n",
    "        Y_predict_test = pd.Series(predicted_test_list, index = test_index)\n",
    "        Y_predict_test = Y_predict_test * test_std + test_mean\n",
    "        Y_actual_test = Y_test.reshape(len(Y_test)) * test_std + test_mean\n",
    "        Y_predict_test = pd.DataFrame(Y_predict_test, index = test_index)\n",
    "        Y_actual_test = pd.DataFrame(Y_actual_test, index = test_index)\n",
    "\n",
    "        # if (show != None):\n",
    "        #   plt.plot(Y_actual_train, label = 'Train Actual')\n",
    "        #   plt.plot(Y_predict_train, label = 'Train predict')\n",
    "        #   plt.plot(Y_actual_test, label = 'Test Actual')\n",
    "        #   plt.plot(Y_predict_test, label = 'Test predict')\n",
    "        #   plt.legend()\n",
    "        #   plt.show()\n",
    "\n",
    "        return Y_actual_train, Y_predict_train, Y_actual_test, Y_predict_test\n",
    "\n",
    "    def obtain_ONE_stock(train, test, show = None):\n",
    "        length = len(train.columns)\n",
    "        actual_train = []\n",
    "        predict_train = []\n",
    "        actual_test = []\n",
    "        predict_test = []\n",
    "        for i in range(length):\n",
    "            train_series = train.iloc[:, i]\n",
    "            test_series = test.iloc[:, i]\n",
    "            Series_actual_train, Series_predict_train, Series_actual_test, Series_predict_test = obtain_ONE_series(train_series, test_series, window_length = 5, show = show)\n",
    "            actual_train.append(Series_actual_train)\n",
    "            predict_train.append(Series_predict_train)\n",
    "            actual_test.append(Series_actual_test)\n",
    "            predict_test.append(Series_predict_test)\n",
    "\n",
    "        final_actual_train = pd.concat(actual_train)\n",
    "        final_actual_train = final_actual_train.groupby(final_actual_train.index).sum()\n",
    "\n",
    "        final_predict_train = pd.concat(predict_train)\n",
    "        final_predict_train = final_predict_train.groupby(final_predict_train.index).sum()\n",
    "\n",
    "        final_actual_test = pd.concat(actual_test)\n",
    "        final_actual_test = final_actual_test.groupby(final_actual_test.index).sum()\n",
    "\n",
    "        final_predict_test = pd.concat(predict_test)\n",
    "        final_predict_test = final_predict_test.groupby(final_predict_test.index).sum()\n",
    "        # if (show != None):\n",
    "        #     plt.plot(final_actual_train, label = 'Train Actual')\n",
    "        #     plt.plot(final_predict_train, label = 'Train predict')\n",
    "        #     plt.plot(final_actual_test, label = 'Test Actual')\n",
    "        #     plt.plot(final_predict_test, label = 'Test predict')\n",
    "        #     plt.legend()\n",
    "        #     plt.show()\n",
    "\n",
    "        return final_actual_train, final_predict_train, final_actual_test, final_predict_test\n",
    "\n",
    "\n",
    "    final_actual_train, final_predict_train, final_actual_test, final_predict_test = obtain_ONE_stock(example_train, example_test, show = True)\n",
    "\n",
    "    Y_result = pd.concat([pd.concat([final_actual_train, final_predict_train], axis = 1), pd.concat([final_actual_test, final_predict_test], axis = 1)], axis = 0)\n",
    "    Y_result.columns = ['Smoothed_Actual', 'Predict']\n",
    "    Y_result = pd.concat([example_actual, Y_result], axis = 1)\n",
    "\n",
    "    store_path = './Data/Parameter_tuning_0.9997/504_Prediction/SSA-CNN/'\n",
    "    def obtain_all(the_index, window_length = 5, show = None):\n",
    "        group_name = group[index[the_index]]\n",
    "        train_All_df, train_files = read_all(train_path + group_name)\n",
    "        test_All_df, test_files = read_all(test_path + group_name)\n",
    "        full_All_df, full_files = read_all(full_path + group_name)\n",
    "        total_length = len(full_All_df)\n",
    "\n",
    "        for i in range(total_length):\n",
    "            stock_name = full_files[i]\n",
    "            train_series = train_All_df[i]\n",
    "            test_series = test_All_df[i]\n",
    "            final_actual_train, final_predict_train, final_actual_test, final_predict_test = obtain_ONE_stock(train_series, test_series, show = show)\n",
    "\n",
    "            actual = full_All_df[i][5:]\n",
    "            Y_result = pd.concat([pd.concat([final_actual_train, final_predict_train], axis = 1), pd.concat([final_actual_test, final_predict_test], axis = 1)], axis = 0)\n",
    "            Y_result.columns = ['Smoothed_Actual', 'Predict']\n",
    "            Y_result = pd.concat([actual, Y_result], axis = 1)\n",
    "            Y_result.to_csv(store_path + group_name + '/' + stock_name)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    obtain_all(idx, show = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
