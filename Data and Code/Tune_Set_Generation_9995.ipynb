{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length are 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 1: Consumer and Service Sectors\n",
    "- Only need to change the index to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "from scipy.linalg import hankel\n",
    "from scipy.linalg import svd\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from SSA_package import SSA\n",
    "train_size = 0.8\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation:\n",
    "- When generating the train set, we only need to run it one time to get the components, which is quite fast\n",
    "- The two parameters that should be tuned for these time_series are: L, and criteria (Because some generate 2 groups, but some generate 4 groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/Grouped/'\n",
    "save_path = './Data/Parameter_tuning_0.9995/63/'\n",
    "group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "index = 0\n",
    "\n",
    "def read_stock(file_name, directory):\n",
    "    stock = pd.read_csv(directory + file_name, header = [0])\n",
    "    index = pd.to_datetime(stock['Date'])\n",
    "    stock.drop('Date', axis = 1)\n",
    "    stock.index = index\n",
    "    stock = stock[['Adj Close']]\n",
    "    return stock\n",
    "\n",
    "def read_all(the_path, index):\n",
    "    All_df = []\n",
    "    files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for name in files:\n",
    "        stock = read_stock(name, path + group[index] + '/')\n",
    "        All_df.append(stock)\n",
    "    return All_df, files\n",
    "\n",
    "# stock_example = read_stock('ALL.AX.csv', path + group[index] + '/')\n",
    "# length = len(stock_example)\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(All_df)\n",
    "window_L = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = stock_example[:int(length*train_size)]\n",
    "# train_index = stock_example.index[int(length*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components_train(train, L = window_L, criteria = 0.9995):\n",
    "    print(len(train))\n",
    "    ssa = SSA(train, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    ssa.plot_combined()\n",
    "    return combined_series\n",
    "\n",
    "def download_train(train, save_path, file_name):\n",
    "    train_index = train.index\n",
    "    components = obtain_components_train(train, L = window_L, criteria = 0.9995)\n",
    "    components = pd.DataFrame(components.T, index = train_index)\n",
    "    components.to_csv(save_path + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_train(save_path + 'Train/' + group[0], 'ALL.AX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generation:\n",
    "- Test Generation is a little bit comple, we need to generate the new points every time based on all the prior series\n",
    "- Hence, we should do for loop 252 times, and just store the last value from each sequence, and then make a csv file to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components(test, L = window_L, criteria = 0.9995):\n",
    "    ssa = SSA(test, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    if (combined_series == 'You should reduce the group number'):\n",
    "        print()\n",
    "\n",
    "        print()\n",
    "    # print(combined_series[:, -1].shape)\n",
    "    # print(combined_series[:, -1])\n",
    "    # ssa.plot_combined()\n",
    "    return combined_series[:, -1]\n",
    "\n",
    "def obtain_test(stock):\n",
    "    test_generated = np.zeros(shape = (252, 2))\n",
    "    test_index = stock.index[1008:]\n",
    "    for i in range(1, 253):\n",
    "        last_series = obtain_components(stock[:1008 + i])\n",
    "        last_series = np.sort(last_series)\n",
    "        test_generated[i - 1] = last_series\n",
    "    test_generated = pd.DataFrame(test_generated, test_index)\n",
    "    return test_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 2: Financial, Healthcare, Technology, and Utilities Sectors\n",
    "- Only need to change the index to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = All_df[0][:int(length*train_size)]\n",
    "train_index = train.index\n",
    "components = obtain_components(train, L = window_L, criteria = 0.9995)\n",
    "components = pd.DataFrame(components.T, index = train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 3: Industrial and Infrastructure Sectors\n",
    "- Only need to change the index to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length are 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 1: Consumer and Service Sectors\n",
    "- Only need to change the index to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "from scipy.linalg import hankel\n",
    "from scipy.linalg import svd\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from SSA_package import SSA\n",
    "train_size = 0.8\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation:\n",
    "- When generating the train set, we only need to run it one time to get the components, which is quite fast\n",
    "- The two parameters that should be tuned for these time_series are: L, and criteria (Because some generate 2 groups, but some generate 4 groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/Grouped/'\n",
    "save_path = './Data/Parameter_tuning_0.9995/252/'\n",
    "group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "index = 0\n",
    "\n",
    "def read_stock(file_name, directory):\n",
    "    stock = pd.read_csv(directory + file_name, header = [0])\n",
    "    index = pd.to_datetime(stock['Date'])\n",
    "    stock.drop('Date', axis = 1)\n",
    "    stock.index = index\n",
    "    stock = stock[['Adj Close']]\n",
    "    return stock\n",
    "\n",
    "def read_all(the_path, index):\n",
    "    All_df = []\n",
    "    files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for name in files:\n",
    "        stock = read_stock(name, path + group[index] + '/')\n",
    "        All_df.append(stock)\n",
    "    return All_df, files\n",
    "\n",
    "# stock_example = read_stock('ALL.AX.csv', path + group[index] + '/')\n",
    "# length = len(stock_example)\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(All_df)\n",
    "window_L = 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = stock_example[:int(length*train_size)]\n",
    "# train_index = stock_example.index[int(length*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components_train(train, L = window_L, criteria = 0.9995):\n",
    "    print(len(train))\n",
    "    ssa = SSA(train, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    # ssa.plot_combined()\n",
    "    return combined_series\n",
    "\n",
    "def download_train(train, save_path, file_name):\n",
    "    train_index = train.index\n",
    "    components = obtain_components_train(train, L = window_L, criteria = 0.9995)\n",
    "    components = pd.DataFrame(components.T, index = train_index)\n",
    "    components.to_csv(save_path + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_train(save_path + 'Train/' + group[0], 'ALL.AX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generation:\n",
    "- Test Generation is a little bit comple, we need to generate the new points every time based on all the prior series\n",
    "- Hence, we should do for loop 252 times, and just store the last value from each sequence, and then make a csv file to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components(test, L = window_L, criteria = 0.9995):\n",
    "    ssa = SSA(test, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    if (combined_series == 'You should reduce the group number'):\n",
    "        print()\n",
    "\n",
    "        print()\n",
    "    # print(combined_series[:, -1].shape)\n",
    "    # print(combined_series[:, -1])\n",
    "    # ssa.plot_combined()\n",
    "    return combined_series[:, -1]\n",
    "\n",
    "def obtain_test(stock):\n",
    "    test_generated = np.zeros(shape = (252, 2))\n",
    "    test_index = stock.index[1008:]\n",
    "    for i in range(1, 253):\n",
    "        last_series = obtain_components(stock[:1008 + i])\n",
    "        last_series = np.sort(last_series)\n",
    "        test_generated[i - 1] = last_series\n",
    "    test_generated = pd.DataFrame(test_generated, test_index)\n",
    "    return test_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 2: Financial, Healthcare, Technology, and Utilities Sectors\n",
    "- Only need to change the index to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 3: Industrial and Infrastructure Sectors\n",
    "- Only need to change the index to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length are 504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 1: Consumer and Service Sectors\n",
    "- Only need to change the index to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "from scipy.linalg import hankel\n",
    "from scipy.linalg import svd\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from SSA_package import SSA\n",
    "train_size = 0.8\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation:\n",
    "- When generating the train set, we only need to run it one time to get the components, which is quite fast\n",
    "- The two parameters that should be tuned for these time_series are: L, and criteria (Because some generate 2 groups, but some generate 4 groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/Grouped/'\n",
    "save_path = './Data/Parameter_tuning_0.9995/504/'\n",
    "group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "index = 0\n",
    "\n",
    "def read_stock(file_name, directory):\n",
    "    stock = pd.read_csv(directory + file_name, header = [0])\n",
    "    index = pd.to_datetime(stock['Date'])\n",
    "    stock.drop('Date', axis = 1)\n",
    "    stock.index = index\n",
    "    stock = stock[['Adj Close']]\n",
    "    return stock\n",
    "\n",
    "def read_all(the_path, index):\n",
    "    All_df = []\n",
    "    files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for name in files:\n",
    "        stock = read_stock(name, path + group[index] + '/')\n",
    "        All_df.append(stock)\n",
    "    return All_df, files\n",
    "\n",
    "# stock_example = read_stock('ALL.AX.csv', path + group[index] + '/')\n",
    "# length = len(stock_example)\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(All_df)\n",
    "window_L = 504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = stock_example[:int(length*train_size)]\n",
    "# train_index = stock_example.index[int(length*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components_train(train, L = window_L, criteria = 0.9995):\n",
    "    print(len(train))\n",
    "    ssa = SSA(train, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    # ssa.plot_combined()\n",
    "    return combined_series\n",
    "\n",
    "def download_train(train, save_path, file_name):\n",
    "    train_index = train.index\n",
    "    components = obtain_components_train(train, L = window_L, criteria = 0.9995)\n",
    "    components = pd.DataFrame(components.T, index = train_index)\n",
    "    components.to_csv(save_path + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_train(save_path + 'Train/' + group[0], 'ALL.AX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generation:\n",
    "- Test Generation is a little bit comple, we need to generate the new points every time based on all the prior series\n",
    "- Hence, we should do for loop 252 times, and just store the last value from each sequence, and then make a csv file to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_components(test, L = window_L, criteria = 0.9995):\n",
    "    ssa = SSA(test, L, criteria= criteria)\n",
    "    U, Sigma, Vt, rank = ssa.decomposition()\n",
    "    index = ssa.calculate_component_contribution()\n",
    "    components = ssa.reconstruction()\n",
    "    # ssa.plot_components()\n",
    "    # ssa.obtain_correlation_matrix()\n",
    "    combined_series = ssa.grouping()\n",
    "    if (combined_series == 'You should reduce the group number'):\n",
    "        print()\n",
    "\n",
    "        print()\n",
    "    # print(combined_series[:, -1].shape)\n",
    "    # print(combined_series[:, -1])\n",
    "    # ssa.plot_combined()\n",
    "    return combined_series[:, -1]\n",
    "\n",
    "def obtain_test(stock):\n",
    "    test_generated = np.zeros(shape = (252, 2))\n",
    "    test_index = stock.index[1008:]\n",
    "    for i in range(1, 253):\n",
    "        last_series = obtain_components(stock[:1008 + i])\n",
    "        last_series = np.sort(last_series)\n",
    "        test_generated[i - 1] = last_series\n",
    "    test_generated = pd.DataFrame(test_generated, test_index)\n",
    "    return test_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 2: Financial, Healthcare, Technology, and Utilities Sectors\n",
    "- Only need to change the index to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Generation For Group 3: Industrial and Infrastructure Sectors\n",
    "- Only need to change the index to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generation and Test Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "length = 1260\n",
    "All_df, files = read_all(path + group[index]+'/', index = index)\n",
    "for i in range(len(All_df)):\n",
    "    train = All_df[i][:int(length*train_size)]\n",
    "    # print(len(train))\n",
    "    download_train(train, save_path + 'Train/' + group[index], files[i])\n",
    "\n",
    "for i in range(len(All_df)):\n",
    "    stock = All_df[i]\n",
    "    test_generated = obtain_test(stock)\n",
    "    test_generated.to_csv(save_path + 'Test/' + group[index] + '/' + files[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
