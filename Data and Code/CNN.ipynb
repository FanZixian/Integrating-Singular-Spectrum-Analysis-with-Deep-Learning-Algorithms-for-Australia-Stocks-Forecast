{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 01:12:33.839472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 01:12:34.499665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "from Window_Generator_package import Window_Generator\n",
    "\n",
    "\n",
    "# stock_example = pd.read_csv(path + 'Data/Grouped/Consumer and Service Sectors/ALL.AX.csv')\n",
    "def read_stock(path, file_name):\n",
    "    stock = pd.read_csv(path + file_name, header = [0])\n",
    "    stock_index = pd.to_datetime(stock['Date'])\n",
    "    stock.index = stock_index\n",
    "    stock = stock.drop('Date', axis = 1)\n",
    "    return stock\n",
    "group = ['Consumer and Service Sectors', 'Financial, Healthcare, Technology, and Utilities Sectors', 'Industrial and Infrastructure Sectors']\n",
    "index = [0, 1, 2]\n",
    "def read_all(the_path):\n",
    "    All_df = []\n",
    "    files = [f for f in os.listdir(the_path) if f.endswith('.csv')]\n",
    "\n",
    "    for name in files:\n",
    "        stock = read_stock(the_path + '/', name)\n",
    "        All_df.append(stock)\n",
    "    return All_df, files\n",
    "All_df_0, files = read_all(path + 'Data/Grouped/' + group[index[0]])\n",
    "stock_example = All_df_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260, 1)\n"
     ]
    }
   ],
   "source": [
    "print(stock_example.shape)\n",
    "train_series = stock_example[:1008].squeeze()\n",
    "test_series = stock_example[1008:].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_series_shape: (1008,)\n",
      "test_series_shape: (252,)\n",
      "X_train: (1003, 5, 1)\n",
      "Y_train: (1003, 1, 1)\n",
      "X_test: (252, 5, 1)\n",
      "Y_test: (252, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "w = Window_Generator(train_series = train_series, test_series = test_series)\n",
    "_, _, train_mean, train_std, test_mean, test_std = w.standardization(show=True)\n",
    "_, _, _, _ = w.window_generation(show = True)\n",
    "X_train, X_test, Y_train, Y_test = w.data_getter()\n",
    "train_denormalized = w.denormalize_train()\n",
    "test_denormalized = w.denormalize_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 30\n",
    "\n",
    "def compile_and_fit(model, X_train, Y_train, patience=5):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(X_train, Y_train, epochs=MAX_EPOCHS, verbose = 0)\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 01:13:06.416769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:06.542540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:06.543016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:06.545255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:06.545627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:06.545944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:07.427839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:07.428363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:07.428377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-31 01:13:07.428791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 01:13:07.428998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def cnn_model(window_length):\n",
    "  cnn = Sequential()\n",
    "  cnn.add(Conv1D(filters=32, kernel_size=window_length, activation='relu', input_shape=(5, 1)))\n",
    "  cnn.add(Dropout(0.3))\n",
    "  cnn.add(Dense(64, activation='relu'))\n",
    "  cnn.add(Dense(1, activation = 'linear'))\n",
    "  return cnn\n",
    "\n",
    "cnn = cnn_model(window_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(cnn, X_train = X_train, Y_train = Y_train)\n",
    "IPython.display.clear_output()\n",
    "train_performance = cnn.evaluate(X_train, Y_train)\n",
    "test_performance = cnn.evaluate(X_test, Y_test)\n",
    "print('Train:', str(train_performance))\n",
    "print('Test:', str(test_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = cnn.predict(X_test)\n",
    "Y_predict = Y_predict.reshape(len(Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As Neural Network doesn't provide the same result each run time, run 5 times and get the average of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = 5):\n",
    "  # The input train and test are all 3D list\n",
    "  predicted_train_list = []\n",
    "  predicted_test_list = []\n",
    "  train_MAE_list = []\n",
    "  test_MAE_list = []\n",
    "  for i in range(5):\n",
    "    cnn = cnn_model(window_length)\n",
    "    history = compile_and_fit(cnn, X_train = X_train, Y_train = Y_train)\n",
    "    # IPython.display.clear_output()\n",
    "    train_performance = cnn.evaluate(X_train, Y_train)[1]\n",
    "    test_performance = cnn.evaluate(X_test, Y_test)[1]\n",
    "    # print('Train:', str(train_performance))\n",
    "    # print('Test:', str(test_performance))\n",
    "    Y_predict_train = cnn.predict(X_train)\n",
    "    Y_predict_train = Y_predict_train.reshape(len(Y_predict_train))\n",
    "    predicted_train_list.append(Y_predict_train)\n",
    "\n",
    "    Y_predict_test = cnn.predict(X_test)\n",
    "    Y_predict_test = Y_predict_test.reshape(len(Y_predict_test))\n",
    "    predicted_test_list.append(Y_predict_test)\n",
    "\n",
    "    train_MAE_list.append(train_performance)\n",
    "    test_MAE_list.append(test_performance)\n",
    "\n",
    "  train_MAE = np.mean(train_MAE_list)\n",
    "  test_MAE = np.mean(test_MAE_list)\n",
    "\n",
    "  predicted_train_list = np.array(predicted_train_list)\n",
    "  predicted_train_list = np.mean(predicted_train_list, axis = 0)\n",
    "  predicted_test_list = np.array(predicted_test_list)\n",
    "  predicted_test_list = np.mean(predicted_test_list, axis = 0)\n",
    "\n",
    "  return predicted_train_list, predicted_test_list, train_MAE, test_MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_list, predicted_test_list, train_MAE, test_MAE = obtain_prediction(X_train, Y_train, X_test, Y_test, window_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_train_list.shape)\n",
    "print(predicted_test_list.shape)\n",
    "print(train_MAE)\n",
    "print(test_MAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
